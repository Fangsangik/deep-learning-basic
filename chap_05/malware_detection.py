import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

import tensorflow as tf
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt

df = pd.read_csv('/Users/hwangsang-ik/Documents/머신러닝/infran_ML_DL-main/datasets/malware.csv', index_col=0)
print(df.head()) # name, md5 => 제거
print(df.tail())
print(df.shape)  # (10000, 57)
print(df['legitimate'].value_counts())
print(df.columns)

df = df.iloc[:, 2:] # iloc => index로 접근
print(df.shape)

y = df['legitimate'].values
x = df.pop('legitimate').values # dataframe어세 legitimate 컬럼 빼버림 / 제외된 값을 y.values에 저장
x = df.values # pop을 하면서 legitimate 컬럼이 제거된 df를 x에 저장
print(x.shape)
print(y.shape)

# train / test split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# Feature Scaling
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)
print(x_train.shape)
print(x_test.shape)

model = tf.keras.Sequential()
model.add(Dense(32, input_shape=(54,), activation='relu')) # input layer
model.add(Dense(16, activation='relu')) # hidden layer
model.add(Dense(1, activation='sigmoid'))  # output layer / 이진 분류 문제이므로 sigmoid 활성화 함수 사용

model.summary()

# 손실함수 - binary_crossentropy
# optimizer - adam
# metrics - accuracy (분류 model이다 보니 accuracy) 사용 가능
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test))

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# 시각화
plt.figure(figsize=(12, 4))
# subplot(행, 열, 위치)
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

y_pred = model.predict(x_test) > 0.5
print(accuracy_score(y_test, y_pred))
